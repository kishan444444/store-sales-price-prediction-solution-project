{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 6, 30, 17, 17, 37, 262339)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06_30_2024_17_17_37.log'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{datetime.now().strftime('%m_%d_%Y_%H_%M_%S')}.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kisha\\\\Desktop\\\\myproject\\\\notebooks\\\\logs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(os.getcwd(),\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\kisha\\\\Desktop\\\\myproject\\\\notebooks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.GoogleAnalyticsCustomerRevenuePrediction.logger import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.GoogleAnalyticsCustomerRevenuePrediction.exception import customexception\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "C:\\Users\\kisha\\AppData\\Local\\Temp\\ipykernel_8200\\1901770474.py\n",
      "division by zero\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "     a=1/0\n",
    "except Exception as e:\n",
    "     _,_,exc_tb=sys.exc_info()\n",
    "     print(exc_tb.tb_lineno)\n",
    "     print(exc_tb.tb_frame.f_code.co_filename)\n",
    "     \n",
    "     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'exceptiom' from 'src.GoogleAnalyticsCustomerRevenuePrediction.exception' (c:\\users\\kisha\\desktop\\myproject\\src\\GoogleAnalyticsCustomerRevenuePrediction\\exception.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGoogleAnalyticsCustomerRevenuePrediction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exceptiom\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'exceptiom' from 'src.GoogleAnalyticsCustomerRevenuePrediction.exception' (c:\\users\\kisha\\desktop\\myproject\\src\\GoogleAnalyticsCustomerRevenuePrediction\\exception.py)"
     ]
    }
   ],
   "source": [
    "from src.GoogleAnalyticsCustomerRevenuePrediction.exception import exceptiom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.logger import logging\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.exception import customexception\n",
    "from sklearn.model_selection import train_test_split\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "class Dataingestionconfig:\n",
    "    raw_data_path:str=os.path.join(\"artifacts\",\"raw.csv\")\n",
    "    train_data_path:str=os.path.join(\"artifacts\",\"train.csv\")\n",
    "    test_data_path:str=os.path.join(\"artifacts\",\"test.csv\")\n",
    "    \n",
    "class Dataingestion:\n",
    "    def __init__(self):\n",
    "        self.ingestion_config=Dataingestionconfig()\n",
    "     \n",
    "    def initiate_data_ingestion(self):\n",
    "        logging.info(\"data_ingestion_started\")\n",
    "        \n",
    "        try:\n",
    "            data=pd.read_csv(Path(os.path.join(\"notebooks/data\",\"stores sales prediction.csv\")))\n",
    "            logging.info(\"I have read the dataset as df\")\n",
    "            \n",
    "            os.makedirs(os.path.dirname(os.path.join(self.ingestion_config.raw_data_path)),exist_ok=t)\n",
    "            data.to_csv(self.ingestion_config.raw_data_path,index=False)\n",
    "            logging.info(\"i have saved the raw dataset in artifacts folder\")\n",
    "            \n",
    "            logging.info(\"here i had perform train_test_split\")\n",
    "            train_data,test_data=train_test_split(data,test_size=0.25)\n",
    "            logging.info(\"train_test_split completed\")\n",
    "            \n",
    "            \n",
    "            data.to_csv(self.ingestion_config.train_data_path,index=False)\n",
    "            data.to_csv(self.ingestion_config.test_data_path,index=False)\n",
    "            logging.info(\"data ingestion part completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.info(\"exception occured at data ingestion stage\")\n",
    "            raise customexception(e,sys)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.exception import customexception\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.logger import logging\n",
    "\n",
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.utils.utils import save_object\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_df=pd.read_csv(r\"C:\\Users\\kisha\\Desktop\\myproject\\artifacts\\train.csv\")\n",
    "test_df=pd.read_csv(r\"C:\\Users\\kisha\\Desktop\\myproject\\artifacts\\test.csv\")\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "            \n",
    "train_df = pd.DataFrame(train_df)\n",
    "test_df=pd.DataFrame(train_df)\n",
    "            \n",
    "mean_value= train_df.loc[:, 'Item_Weight'].mean()\n",
    "train_df['Item_Weight'].fillna(value=mean_value, inplace=True) \n",
    "            \n",
    "mean_value= test_df.loc[:, 'Item_Weight'].mean()\n",
    "test_df['Item_Weight'].fillna(value=mean_value, inplace=True) \n",
    "            \n",
    "            \n",
    "import re\n",
    "# Function to extract numeric part from a string\n",
    "def extract_numeric(value):\n",
    "    numeric_part = re.findall(r'\\d+', value)  # Find all numeric parts\n",
    "    return int(numeric_part[0]) if numeric_part else None  # Convert to int if found\n",
    "            # Apply the function to extract numeric part and convert to int\n",
    "            \n",
    "                \n",
    "train_df['Item_Identifier'] = train_df['Item_Identifier'].apply(extract_numeric)\n",
    "test_df['Item_Identifier'] = test_df['Item_Identifier'].apply(extract_numeric)\n",
    "            \n",
    "input_feature_train_df = train_df.drop(\"Outlet_Establishment_Year\",axis=1)\n",
    "input_feature_train_df = train_df.drop(\"Outlet_Identifier\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>9.300</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.920</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>17.500</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.016760</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>19.200</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>8.930</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>22</td>\n",
       "      <td>6.865</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.056783</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>214.5218</td>\n",
       "      <td>1987</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2778.3834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>36</td>\n",
       "      <td>8.380</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.046982</td>\n",
       "      <td>Baking Goods</td>\n",
       "      <td>108.1570</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>549.2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>29</td>\n",
       "      <td>10.600</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.035186</td>\n",
       "      <td>Health and Hygiene</td>\n",
       "      <td>85.1224</td>\n",
       "      <td>2004</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>1193.1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>46</td>\n",
       "      <td>7.210</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.145221</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>103.1332</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>1845.5976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>1</td>\n",
       "      <td>14.800</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.044878</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>75.4670</td>\n",
       "      <td>1997</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>765.6700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8523 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0                  15        9.300          Low Fat         0.016047   \n",
       "1                   1        5.920          Regular         0.019278   \n",
       "2                  15       17.500          Low Fat         0.016760   \n",
       "3                   7       19.200          Regular         0.000000   \n",
       "4                  19        8.930          Low Fat         0.000000   \n",
       "...               ...          ...              ...              ...   \n",
       "8518               22        6.865          Low Fat         0.056783   \n",
       "8519               36        8.380          Regular         0.046982   \n",
       "8520               29       10.600          Low Fat         0.035186   \n",
       "8521               46        7.210          Regular         0.145221   \n",
       "8522                1       14.800          Low Fat         0.044878   \n",
       "\n",
       "                  Item_Type  Item_MRP  Outlet_Establishment_Year Outlet_Size  \\\n",
       "0                     Dairy  249.8092                       1999      Medium   \n",
       "1               Soft Drinks   48.2692                       2009      Medium   \n",
       "2                      Meat  141.6180                       1999      Medium   \n",
       "3     Fruits and Vegetables  182.0950                       1998         NaN   \n",
       "4                 Household   53.8614                       1987        High   \n",
       "...                     ...       ...                        ...         ...   \n",
       "8518            Snack Foods  214.5218                       1987        High   \n",
       "8519           Baking Goods  108.1570                       2002         NaN   \n",
       "8520     Health and Hygiene   85.1224                       2004       Small   \n",
       "8521            Snack Foods  103.1332                       2009      Medium   \n",
       "8522            Soft Drinks   75.4670                       1997       Small   \n",
       "\n",
       "     Outlet_Location_Type        Outlet_Type  Item_Outlet_Sales  \n",
       "0                  Tier 1  Supermarket Type1          3735.1380  \n",
       "1                  Tier 3  Supermarket Type2           443.4228  \n",
       "2                  Tier 1  Supermarket Type1          2097.2700  \n",
       "3                  Tier 3      Grocery Store           732.3800  \n",
       "4                  Tier 3  Supermarket Type1           994.7052  \n",
       "...                   ...                ...                ...  \n",
       "8518               Tier 3  Supermarket Type1          2778.3834  \n",
       "8519               Tier 2  Supermarket Type1           549.2850  \n",
       "8520               Tier 2  Supermarket Type1          1193.1136  \n",
       "8521               Tier 3  Supermarket Type2          1845.5976  \n",
       "8522               Tier 1  Supermarket Type1           765.6700  \n",
       "\n",
       "[8523 rows x 11 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_feature_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.exception import customexception\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.logger import logging\n",
    "\n",
    "from sklearn.impute import SimpleImputer ## HAndling Missing Values\n",
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.preprocessing import OrdinalEncoder # Ordinal Encoding\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from src.GoogleAnalyticsCustomerRevenuePrediction.utils.utils import save_object\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Data_transformation_config:\n",
    "    preprocessor_obj_file_path=os.path.join(\"artifacts\",\"preprocessor.pkl\")\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self):\n",
    "        self.data_transformation_config=Data_transformation_config()\n",
    "       \n",
    "    def get_data_transformation(self):\n",
    "        \n",
    "        try:\n",
    "            #Define which columns should be ordinal-encoded and which should be scaled\n",
    "            categorical_cols=['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type',\n",
    "                             'Outlet_Type']\n",
    "            numerical_cols=['Item_Identifier', 'Item_Weight', 'Item_Visibility', 'Item_MRP']\n",
    "            \n",
    "            # Define the custom ranking for each ordinal variable\n",
    "            \n",
    "            Item_Fat_Content_map=[\"Low Fat\",\"Regular\",\"LF\",\"reg\",\"low fat\"]\n",
    "            Item_Type_map=[\"Fruits and Vegetables\",\"Snack Foods\",\"Household\",\"Frozen Foods\",\"Dairy\",\"Canned\",\"Baking Goods\",\"Health and Hygiene\",\n",
    "                           \"Soft Drinks\",\"Meat\",\"Breads\",\"Hard Drinks\",\"Others\",\"Starchy Foods\",\"Breakfast\",\"Seafood\"]\n",
    "            Outlet_Size_map=[\"Medium\",\"medium\",\"Small\",\"High\"]\n",
    "            Outlet_Location_Type_map=[\"Tier 3\",\"Tier 2\",\"Tier 1\"]\n",
    "            Outlet_Type_map=[\"Supermarket Type1\",\"Grocery Store\",\"Supermarket Type3\",\"Supermarket Type2\"]\n",
    "            \n",
    "            \n",
    "            logging.info('Pipeline Initiated')\n",
    "            \n",
    "            ## Numerical Pipeline\n",
    "            num_pipeline=Pipeline(\n",
    "                steps=[\n",
    "                ('imputer',SimpleImputer(strategy='median')),\n",
    "                ('scaler',StandardScaler())\n",
    "\n",
    "                ]\n",
    "\n",
    "            )\n",
    "            \n",
    "            # Categorigal Pipeline\n",
    "            cat_pipeline=Pipeline(\n",
    "                steps=[\n",
    "                ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "                ('ordinalencoder',OrdinalEncoder(categories=[Item_Fat_Content_map,Item_Type_map,Outlet_Size_map,Outlet_Location_Type_map,Outlet_Type_map])),\n",
    "                ('scaler',StandardScaler())\n",
    "                ]\n",
    "\n",
    "            )\n",
    "            \n",
    "            preprocessor=ColumnTransformer([\n",
    "            ('num_pipeline',num_pipeline,numerical_cols),\n",
    "            ('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "            ])\n",
    "            \n",
    "            return preprocessor\n",
    "           \n",
    "        except Exception as e:\n",
    "            logging.info(\"Exception occured in initiating data transformation\")\n",
    "            raise customexception(e,sys)\n",
    "        \n",
    "    def initiated_data_transformation(self,train_path,test_path):\n",
    "        \n",
    "        try:\n",
    "            train_df=pd.read_csv(train_path)\n",
    "            test_df=pd.read_csv(test_path)\n",
    "            \n",
    "            logging.info(\"read train and test data completed\")\n",
    "            logging.info(f'Train Dataframe Head : \\n{train_df.head().to_string()}')\n",
    "            logging.info(f'Test Dataframe Head : \\n{test_df.head().to_string()}')\n",
    "            \n",
    "            preprocessing_obj=self.get_data_transformation()\n",
    "            \n",
    "            train_df = pd.DataFrame(train_df)\n",
    "            test_df=pd.DataFrame(train_df)\n",
    "            \n",
    "            mean_value= train_df.loc[:, 'Item_Weight'].mean()\n",
    "            train_df['Item_Weight'].fillna(value=mean_value, inplace=True) \n",
    "            \n",
    "            mean_value= test_df.loc[:, 'Item_Weight'].mean()\n",
    "            test_df['Item_Weight'].fillna(value=mean_value, inplace=True) \n",
    "            \n",
    "            \n",
    "            import re\n",
    "            # Function to extract numeric part from a string\n",
    "            def extract_numeric(value):\n",
    "                numeric_part = re.findall(r'\\d+', value)  # Find all numeric parts\n",
    "                return int(numeric_part[0]) if numeric_part else None  # Convert to int if found\n",
    "            # Apply the function to extract numeric part and convert to int\n",
    "                \n",
    "            train_df['Item_Identifier'] = train_df['Item_Identifier'].apply(extract_numeric)\n",
    "            test_df['Item_Identifier'] = test_df['Item_Identifier'].apply(extract_numeric)\n",
    "            \n",
    "            input_feature_train_df = train_df.drop(\"Outlet_Establishment_Year\",axis=1)\n",
    "            input_feature_train_df = train_df.drop(\"Outlet_Identifier\",axis=1)\n",
    "            input_feature_train_df = train_df.drop(\"Item_Outlet_Sales\",axis=1)\n",
    "            target_feature_train_df=train_df[\"Item_Outlet_Sales\"]\n",
    "            \n",
    "            \n",
    "            input_feature_test_df = test_df.drop(\"Outlet_Establishment_Year\",axis=1)\n",
    "            input_feature_test_df = test_df.drop(\"Outlet_Identifier\",axis=1)\n",
    "            input_feature_test_df = test_df.drop(\"Item_Outlet_Sales\",axis=1)\n",
    "            target_feature_test_df=test_df[\"Item_Outlet_Sales\"]\n",
    "            \n",
    "            \n",
    "            \n",
    "            input_feature_train_arr=preprocessing_obj.fit_transform( input_feature_train_df)\n",
    "            input_feature_test_arr=preprocessing_obj.transform(input_feature_test_df)\n",
    "            \n",
    "            logging.info(\"Applying preprocessing object on training and testing datasets.\")\n",
    "            \n",
    "            \n",
    "            \n",
    "            train_arr = np.c_[input_feature_train_arr, np.array(target_feature_train_df)]\n",
    "            test_arr = np.c_[input_feature_test_arr,np.array(target_feature_test_df)]\n",
    "            \n",
    "            save_object(file_path=self.data_transformation_config.preprocessor_obj_file_path,\n",
    "                        obj=preprocessing_obj\n",
    "                        )\n",
    "            \n",
    "            logging.info(\"preprocessing pickle file saved\")\n",
    "            \n",
    "            return (\n",
    "                train_arr,\n",
    "                test_arr\n",
    "            )\n",
    "        \n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.info(\"Exception occured in initiating data transformation\")\n",
    "            raise customexception(e,sys)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
